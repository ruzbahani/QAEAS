{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import pennylane as qml\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 1369\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Current GPU memory usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "try:\n",
    "    available_devices = qml.device.all_devices()\n",
    "    print(f\"Available quantum devices: {available_devices}\")\n",
    "except:\n",
    "    from pennylane import devices\n",
    "    print(f\"PennyLane devices module available: {dir(devices)[:10]}...\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "try:\n",
    "    from dataloader import Ali_DataLoader\n",
    "    from dataset_analyzer import DatasetAnalyzer, analyze_cifar10_dataset\n",
    "    print(\"Dataloader modules are available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure dataloader.py is in your working directory.\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "try:\n",
    "    from target_resnet20 import ResNet20, train_target_model1_resnet20\n",
    "    print(\"Target model 1:ResNet20 is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure target_resnet20.py is in your working directory.\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "try:\n",
    "    from target_efficientnet_b0 import EfficientNetB0, train_target_model2_efficientnet_b0\n",
    "    print(\"Target model 2: EfficientNetB0 is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure target_efficientnet_b0.py is in your working directory.\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "try:\n",
    "    from quantum_base_modifier import QuantumBaseModifier\n",
    "    print(\"1.Quantum ensemble member -quantum_base_modifier- specialized in low-frequency perturbations module is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_base_modifier.py is in your working directory.\")\n",
    "try:\n",
    "    from quantum_texture_attacker import QuantumTextureAttacker\n",
    "    print(\"2.Quantum ensemble member -quantum_texture_attacker- specialized in texture-based perturbations module is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_texture_attacker.py is in your working directory.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    from quantum_edge_disruptor import QuantumEdgeDisruptor\n",
    "    print(\"3.Quantum ensemble member specialized in edge and detail disruption module is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_edge_disruptor.py is in your working directory.\")\n",
    "\n",
    "try:\n",
    "    from quantum_color_distorter import QuantumColorDistorter\n",
    "    print(\"4.Quantum ensemble member specialized in color relationship disruption module is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_color_distorter.py is in your working directory.\")\n",
    "try:\n",
    "    from quantum_focal_attacker import QuantumFocalAttacker\n",
    "    print(\"5.Quantum ensemble member specialized in attacking sensitive regions module is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_focal_attacker.py is in your working directory.\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "try:\n",
    "    from quantum_ensemble_manager import QuantumEnsembleManager\n",
    "    print(\"Master class for managing the quantum ensemble of adversarial attackers is available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"You may need to ensure quantum_ensemble_manager.py is in your working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data5\"\n",
    "results_dir = \"quantum_ensemble_results\"\n",
    "target_model_1_train_result = os.path.join('target model 1 training result')\n",
    "os.makedirs(os.path.join(target_model_1_train_result), exist_ok=True)\n",
    "target_model_2_train_result = os.path.join('target model 2 training result')\n",
    "os.makedirs(os.path.join(target_model_2_train_result), exist_ok=True)\n",
    "data_res= os.path.join('dataset analysis')\n",
    "os.makedirs(os.path.join(data_res), exist_ok=True)\n",
    "data_dir = os.path.join(data_dir)\n",
    "print(f\"Loading CIFAR-10 dataset from {data_dir}\")\n",
    "target_model_1_path = os.path.join('target_model_1', 'resnet20_best.pth')\n",
    "target_model_2_path = os.path.join('target_model_2', 'efficientnet_b0_best.pth')\n",
    "run_name = f\"experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(os.path.join(results_dir, run_name), exist_ok=True)\n",
    "data_mydir=data_dir                     \n",
    "batch_size_d = 64                      \n",
    "num_workers_d=0                      \n",
    "shuffle_d=True                        \n",
    "pin_memory_d=True\n",
    "augmentation_type_d='none'          # 'standard', 'advanced', 'randaugment', 'mixup', 'cutout', 'none'\n",
    "train_percent_d=0.80                    \n",
    "val_percent_d=0.10                     \n",
    "test_percent_d=0.10                   \n",
    "subset_percent_d=100\n",
    "\n",
    "batch_size_t = 64\n",
    "epochs_t = 300\n",
    "run_name_t=run_name,\n",
    "lr_t=0.001\n",
    "weight_decay_t=5e-4\n",
    "patience_t=15\n",
    "scheduler_type_t='plateau' #Type of learning rate scheduler ('plateau', 'cosine', 'onecycle')\n",
    "save_every_t=35\n",
    "mixup_alpha_t=0.2\n",
    "\n",
    "batch_size_t2 = 64\n",
    "epochs_t2 = 300\n",
    "run_name_t2=run_name,\n",
    "lr_t2=0.008\n",
    "weight_decay_t2=5e-4\n",
    "patience_t2=15\n",
    "scheduler_type_t2='cosine' #Type of learning rate scheduler ('plateau', 'cosine', 'onecycle')\n",
    "save_every_t2=35\n",
    "mixup_alpha_t2=0.2\n",
    "\n",
    "batch_size_ens = 64\n",
    "epsilon_ens = 0.01  \n",
    "epochs_ens = 50\n",
    "save_every_ens = 10\n",
    "vis_every=25\n",
    "eval_samples_ens = 5000\n",
    "target_class_ens= None\n",
    "print(f\"Run name: {run_name}\")\n",
    "print(f\"Results save path: {os.path.join(results_dir, run_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading CIFAR-10 dataset from {data_dir}\")\n",
    "data_loader = Ali_DataLoader(\n",
    "    data_dir=data_mydir,               \n",
    "    batch_size=batch_size_d,                     \n",
    "    random_seed=42,                    \n",
    "    shuffle=shuffle_d,                    \n",
    "    num_workers=num_workers_d,                     \n",
    "    pin_memory=pin_memory_d,                   \n",
    "    classes=None,                       \n",
    "    augmentation_type=augmentation_type_d,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Splitting dataset into train/validation/test sets...\")\n",
    "train_loader, val_loader, test_loader = data_loader.load_data(\n",
    "    train_percent=train_percent_d,    \n",
    "    val_percent=val_percent_d,       \n",
    "    test_percent=test_percent_d,\n",
    "    subset_percent= subset_percent_d   \n",
    ")\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"Min value: {images.min()}\")\n",
    "print(f\"Max value: {images.max()}\")\n",
    "print(f\"Mean value: {images.mean()}\")\n",
    "print(f\"Std value: {images.std()}\")\n",
    "for i in range(3):\n",
    "    print(f\"Channel {i} - Mean: {images[:, i].mean()}, Std: {images[:, i].std()}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "\n",
    "\n",
    "class_names = data_loader.get_class_names()\n",
    "print(f\"Class names: {class_names}\")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Data type: {images.dtype}\")\n",
    "print(f\"Value range: [{images.min().item():.4f}, {images.max().item():.4f}]\")\n",
    "def visualize_batch(dataloader, num_samples=5):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:num_samples]\n",
    "    labels = labels[:num_samples]\n",
    "    images = images.numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    class_names = data_loader.get_class_names()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        axs[i].imshow(images[i])\n",
    "        if isinstance(labels[i], torch.Tensor):\n",
    "            label_idx = labels[i].item()\n",
    "        else:\n",
    "            label_idx = labels[i]\n",
    "        axs[i].set_title(class_names[label_idx])\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "print(\"\\nCalculating class distribution...\")\n",
    "train_dist = data_loader.get_class_distribution(train_loader)\n",
    "val_dist = data_loader.get_class_distribution(val_loader)\n",
    "test_dist = data_loader.get_class_distribution(test_loader)\n",
    "print(\"Training set class distribution:\")\n",
    "for class_name, count in train_dist.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(train_dist.keys(), train_dist.values())\n",
    "plt.title(\"Training Set Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(val_dist.keys(), val_dist.values())\n",
    "plt.title(\"Validation Set Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(test_dist.keys(), test_dist.values())\n",
    "plt.title(\"Test Set Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(data_res, 'cifar10_class_distribution.png'))\n",
    "plt.show()\n",
    "print(\"Displaying samples from training data with advanced augmentation:\")\n",
    "visualize_batch(train_loader)\n",
    "print(\"Displaying samples from validation data (without augmentation):\")\n",
    "visualize_batch(val_loader)\n",
    "train_distribution = data_loader.get_class_distribution(train_loader)\n",
    "print(\"Class distribution in training data:\")\n",
    "for class_name, count in train_distribution.items():\n",
    "    print(f\"{class_name}: {count}\")\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_dataset = analyze_cifar10_dataset(data_loader, train_loader, val_loader, test_loader, data_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Model 1 (ResNet20) Training & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_1_exists = os.path.exists(target_model_1_path)\n",
    "def evaluate_model_1(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 10\n",
    "    class_total = [0] * 10\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating model\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                class_correct[label] += (pred == label).item()\n",
    "                class_total[label] += 1\n",
    "    accuracy = 100 * correct / total\n",
    "    class_accuracies = [100 * class_correct[i] / max(1, class_total[i]) for i in range(10)]\n",
    "    return accuracy, class_accuracies\n",
    "print(f\"Checking for existing model at: {target_model_1_path}\")\n",
    "if target_model_1_exists:\n",
    "    print(\"Pre-trained model found! Loading model...\")\n",
    "    checkpoint_1 = torch.load(target_model_1_path, map_location=device)\n",
    "    target_model_1 = ResNet20(num_classes=10).to(device)\n",
    "    if 'model_state_dict' in checkpoint_1:\n",
    "        target_model_1.load_state_dict(checkpoint_1['model_state_dict'])\n",
    "    else:\n",
    "        target_model_1.load_state_dict(checkpoint_1)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    accuracy, class_accuracies = evaluate_model_1(target_model_1, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {class_accuracies[i]:.2f}%\")\n",
    "    \n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(class_names, class_accuracies)\n",
    "    plt.title(\"Per-Class Accuracy on Test Set\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(target_model_1_train_result, 'target_model_1_class_accuracy.png'))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No pre-trained model found. Training a new model...\")\n",
    "    print(\"Starting the data augmentation process to train the target model in a robust manner...\")\n",
    "    print(\"Data augmentation techniques have been applied to the training dataset.\")\n",
    "    print(\"\\nStarting model training...\")\n",
    "    print(\"This may take some time. Training progress will be displayed below:\")\n",
    "    target_model_1 = train_target_model1_resnet20(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        run_name=run_name_t,\n",
    "        epochs=epochs_t,  \n",
    "        lr=lr_t,\n",
    "        weight_decay=weight_decay_t,\n",
    "        patience=patience_t,\n",
    "        scheduler_type=scheduler_type_t,\n",
    "        save_every=save_every_t,\n",
    "        mixup_alpha=mixup_alpha_t\n",
    "    )\n",
    "    print(\"\\nModel training completed!\")\n",
    "    print(\"\\nEvaluating newly trained model...\")\n",
    "    accuracy, class_accuracies = evaluate_model_1(target_model_1, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {class_accuracies[i]:.2f}%\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(class_names, class_accuracies)\n",
    "    plt.title(\"Per-Class Accuracy on Test Set\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(target_model_1_train_result, 'target_model_1_class_accuracy.png'))\n",
    "    plt.show()\n",
    "print(\"\\nModel architecture:\")\n",
    "print(target_model_1)\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    summary_str = str(summary(target_model_1, (3, 32, 32), device=str(device)))\n",
    "    with open(os.path.join(target_model_1_train_result, 'model_summary.txt'), 'w') as f:\n",
    "        f.write(summary_str)\n",
    "    print(f\"Detailed model summary saved to {os.path.join(target_model_1_train_result, 'model_summary.txt')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate detailed model summary: {e}\")\n",
    "print(\"\\nTesting model on a few sample images:\")\n",
    "test_batch = next(iter(test_loader))\n",
    "test_images, test_labels = test_batch\n",
    "test_images = test_images[:5].to(device)  \n",
    "test_labels = test_labels[:5].to(device)\n",
    "target_model_1.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = target_model_1(test_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    img = test_images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2470, 0.2435, 0.2616])\n",
    "    img = img * std + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    correct = predicted[i] == test_labels[i]\n",
    "    color = \"green\" if correct else \"red\"\n",
    "    plt.title(f\"True: {class_names[test_labels[i]]}\\nPred: {class_names[predicted[i]]}\", \n",
    "              color=color)\n",
    "    plt.axis('off')\n",
    "plt.savefig(os.path.join(target_model_1_train_result, 'model_predictions.png'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Model 2 (EfficientNet-B0) Training & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_2_exists = os.path.exists(target_model_2_path)\n",
    "\n",
    "def evaluate_model_2(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 10\n",
    "    class_total = [0] * 10\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating model\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                class_correct[label] += (pred == label).item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    class_accuracies = [100 * class_correct[i] / max(1, class_total[i]) for i in range(10)]\n",
    "    \n",
    "    return accuracy, class_accuracies\n",
    "\n",
    "print(f\"Checking for existing model at: {target_model_2_path}\")\n",
    "\n",
    "if target_model_2_exists:\n",
    "    print(\"Pre-trained model found! Loading model...\")\n",
    "    checkpoint_2 = torch.load(target_model_2_path, map_location=device)\n",
    "    \n",
    "    target_model_2 = EfficientNetB0(num_classes=10).to(device)\n",
    "    \n",
    "    if 'model_state_dict' in checkpoint_2:\n",
    "        target_model_2.load_state_dict(checkpoint_2['model_state_dict'])\n",
    "    else:\n",
    "        target_model_2.load_state_dict(checkpoint_2)\n",
    "    \n",
    "    print(\"Model loaded successfully.\")\n",
    "    \n",
    "    print(\"Evaluating model on test set...\")\n",
    "    accuracy, class_accuracies = evaluate_model_2(target_model_2, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {class_accuracies[i]:.2f}%\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(class_names, class_accuracies)\n",
    "    plt.title(\"Per-Class Accuracy on Test Set\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(target_model_2_train_result, 'target_model_2_class_accuracy.png'))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No pre-trained model found. Training a new model...\")\n",
    "    \n",
    "    print(\"Data augmentation techniques have been applied to the training dataset.\")\n",
    "    print(\"\\nStarting model training...\")\n",
    "    print(\"This may take some time. Training progress will be displayed below:\")\n",
    "    \n",
    "    target_model_2 = train_target_model2_efficientnet_b0(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        run_name=run_name_t2,\n",
    "        epochs=epochs_t2,\n",
    "        lr=lr_t2,\n",
    "        weight_decay=weight_decay_t2,\n",
    "        patience=patience_t2,\n",
    "        scheduler_type=scheduler_type_t2,\n",
    "        save_every=save_every_t2,\n",
    "        mixup_alpha=mixup_alpha_t2\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel training completed!\")\n",
    "    \n",
    "    print(\"\\nEvaluating newly trained model...\")\n",
    "    accuracy, class_accuracies = evaluate_model_2(target_model_2, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {class_accuracies[i]:.2f}%\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(class_names, class_accuracies)\n",
    "    plt.title(\"Per-Class Accuracy on Test Set\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(target_model_2_train_result, 'target_model_2_class_accuracy.png'))\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "print(target_model_2)\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    summary_str = str(summary(target_model_2, (3, 32, 32), device=str(device)))\n",
    "    \n",
    "    with open(os.path.join(target_model_2_train_result, 'model_summary.txt'), 'w') as f:\n",
    "        f.write(summary_str)\n",
    "    \n",
    "    print(f\"Detailed model summary saved to {os.path.join(target_model_2_train_result, 'model_summary.txt')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate detailed model summary: {e}\")\n",
    "\n",
    "print(\"\\nTesting model on a few sample images:\")\n",
    "\n",
    "test_batch = next(iter(test_loader))\n",
    "test_images, test_labels = test_batch\n",
    "test_images = test_images[:5].to(device)\n",
    "test_labels = test_labels[:5].to(device)\n",
    "\n",
    "target_model_2.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = target_model_2(test_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    img = test_images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2470, 0.2435, 0.2616])\n",
    "    img = img * std + mean\n",
    "    \n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    correct = predicted[i] == test_labels[i]\n",
    "    color = \"green\" if correct else \"red\"\n",
    "    plt.title(f\"True: {class_names[test_labels[i]]}\\nPred: {class_names[predicted[i]]}\", \n",
    "              color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig(os.path.join(target_model_2_train_result, 'model_predictions.png'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_1 = ResNet20(num_classes=10).to(device)\n",
    "checkpoint_1 = torch.load(target_model_1_path, map_location=device, weights_only=False)\n",
    "if 'model_state_dict' in checkpoint_1:\n",
    "    target_model_1.load_state_dict(checkpoint_1['model_state_dict'])\n",
    "else:\n",
    "    target_model_1.load_state_dict(checkpoint_1)\n",
    "target_model_1.eval()\n",
    "for param in target_model_1.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"Target model 1:ResNet20 loaded successfully.\")\n",
    "def evaluate_model_1(model, dataloader, num_samples=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if num_samples is not None and total >= num_samples:\n",
    "                break\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "accuracy = evaluate_model_1(target_model_1, test_loader)\n",
    "print(f\"Target model 1:ResNet20 accuracy on test data: {accuracy:.2f}%\")\n",
    "print(\"\\nTarget model 1:ResNet20 ready for adversarial attacks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_2 = EfficientNetB0(num_classes=10).to(device)\n",
    "checkpoint_2 = torch.load(target_model_2_path, map_location=device, weights_only=False)\n",
    "if 'model_state_dict' in checkpoint_2:\n",
    "    target_model_2.load_state_dict(checkpoint_2['model_state_dict'])\n",
    "else:\n",
    "    target_model_2.load_state_dict(checkpoint_2)\n",
    "target_model_2.eval()\n",
    "for param in target_model_2.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"Target model 2:EfficientNet_B0 loaded successfully.\")\n",
    "def evaluate_model_2(model, dataloader, num_samples=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if num_samples is not None and total >= num_samples:\n",
    "                break\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "accuracy = evaluate_model_2(target_model_2, test_loader)\n",
    "print(f\"Target model 2:EfficientNet_B0 accuracy on test data: {accuracy:.2f}%\")\n",
    "print(\"\\nTarget model 2:EfficientNet_B0 ready for adversarial attacks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_ensemble_manager import QuantumEnsembleManager\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_image = test_images[0].to(device)  \n",
    "test_label = test_labels[0].item()\n",
    "print(\"Testing QuantumBaseModifier...\")\n",
    "base_modifier = QuantumBaseModifier(n_qubits=4, n_layers=6, epsilon=epsilon_ens, device=device).to(device)\n",
    "base_perturbation, base_adv_image = base_modifier(test_image.unsqueeze(0))\n",
    "base_modifier.visualize_perturbation(\n",
    "    test_image.cpu(),\n",
    "    base_perturbation[0].cpu(),\n",
    "    base_adv_image[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"base_modifier_test.png\")\n",
    ")\n",
    "print(\"Testing QuantumTextureAttacker...\")\n",
    "texture_attacker = QuantumTextureAttacker(n_qubits=4, n_layers=5, epsilon=epsilon_ens, device=device).to(device)\n",
    "texture_perturbation, texture_adv_image = texture_attacker(test_image.unsqueeze(0))\n",
    "texture_attacker.visualize_perturbation(\n",
    "    test_image.cpu(),\n",
    "    texture_perturbation[0].cpu(),\n",
    "    texture_adv_image[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"texture_attacker_test.png\")\n",
    ")\n",
    "texture_attacker.visualize_gabor_responses(\n",
    "    test_image.cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"gabor_responses_test.png\")\n",
    ")\n",
    "print(\"Testing QuantumEdgeDisruptor...\")\n",
    "edge_disruptor = QuantumEdgeDisruptor(n_qubits=3, n_layers=4, epsilon=epsilon_ens, device=device).to(device)\n",
    "edge_perturbation, edge_adv_image = edge_disruptor(test_image.unsqueeze(0))\n",
    "edge_disruptor.visualize_perturbation(\n",
    "    test_image.cpu(),\n",
    "    edge_perturbation[0].cpu(),\n",
    "    edge_adv_image[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"edge_disruptor_test.png\")\n",
    ")\n",
    "edge_disruptor.visualize_wavelet_decomposition(\n",
    "    test_image.cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"wavelet_decomposition_test.png\")\n",
    ")\n",
    "print(\"Testing QuantumColorDistorter...\")\n",
    "color_distorter = QuantumColorDistorter(n_qubits=3, n_layers=4, epsilon=epsilon_ens, device=device).to(device)\n",
    "color_perturbation, color_adv_image = color_distorter(test_image.unsqueeze(0))\n",
    "color_distorter.visualize_perturbation(\n",
    "    test_image.cpu(),\n",
    "    color_perturbation[0].cpu(),\n",
    "    color_adv_image[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"color_distorter_test.png\")\n",
    ")\n",
    "color_distorter.visualize_colorspaces(\n",
    "    test_image.cpu(),\n",
    "    color_adv_image[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"colorspaces_test.png\")\n",
    ")\n",
    "print(\"Testing QuantumFocalAttacker...\")\n",
    "focal_attacker = QuantumFocalAttacker(target_model=target_model_1, n_qubits=3, n_layers=6, n_focal_regions=6, epsilon=epsilon_ens, device=device).to(device)\n",
    "focal_perturbation, focal_adv_image, gradcam_maps = focal_attacker(test_image.unsqueeze(0))\n",
    "focal_attacker.visualize_perturbation(\n",
    "    test_image.cpu(),\n",
    "    focal_perturbation[0].cpu(),\n",
    "    focal_adv_image[0].cpu(),\n",
    "    gradcam_maps[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"focal_attacker_test.png\")\n",
    ")\n",
    "focal_attacker.visualize_focal_clusters(\n",
    "    test_image.cpu(),\n",
    "    gradcam_maps[0].cpu(),\n",
    "    filename=os.path.join(results_dir, run_name, \"focal_clusters_test.png\")\n",
    ")\n",
    "print(\"All ensemble members tested successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_manager = QuantumEnsembleManager(\n",
    "    target_model=target_model_1,\n",
    "    device=device,\n",
    "    epsilon=epsilon_ens,\n",
    "    run_name=run_name\n",
    ")\n",
    "print(\"Quantum Ensemble Manager created successfully.\")\n",
    "test_batch, test_labels = next(iter(test_loader))\n",
    "test_batch = test_batch.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "adv_images, perturbation, member_outputs, weights = ensemble_manager(test_batch)\n",
    "print(f\"Initial ensemble weights: {weights.detach().cpu().numpy()}\")\n",
    "print(f\"Average perturbation norm: {torch.norm(perturbation, p=2, dim=(1,2,3)).mean().item():.4f}\")\n",
    "with torch.no_grad():\n",
    "    original_outputs = target_model_1(test_batch)\n",
    "    adversarial_outputs = target_model_1(adv_images) \n",
    "    orig_preds = torch.argmax(original_outputs, dim=1)\n",
    "    adv_preds = torch.argmax(adversarial_outputs, dim=1)\n",
    "    success_rate = (orig_preds != adv_preds).float().mean().item() * 100\n",
    "print(f\"Initial attack success rate: {success_rate:.2f}%\")\n",
    "ensemble_manager.visualize_ensemble_attack(\n",
    "    test_batch[0],\n",
    "    test_labels[0].item(),\n",
    "    os.path.join(results_dir, run_name, \"ensemble_attack_test.png\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_metrics = ensemble_manager.train_model(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=epochs_ens,\n",
    "        vis_every=save_every_ens,\n",
    "        save_every=save_every_ens,\n",
    "        target_class= 3\n",
    "    )\n",
    "    print(\"Quantum ensemble training completed successfully!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")\n",
    "    # Save current model state\n",
    "    ensemble_manager.save_model('interrupted_model.pth')\n",
    "    print(\"Current model state saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_manager.visualize_kalman_filter(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ensemble_manager.load_model('best_model.pth')\n",
    "    print(\"Best model loaded.\")\n",
    "except:\n",
    "    print(\"Best model not found, using current model.\")\n",
    "eval_results = ensemble_manager.evaluate_on_dataset(\n",
    "    test_loader,\n",
    "    num_samples=eval_samples_ens\n",
    ")\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(f\"Overall Attack Success Rate: {eval_results['success_rate']:.2f}%\")\n",
    "print(f\"Perturbation Norm: {eval_results['perturbation_norm']:.4f}\")\n",
    "print(f\"Prediction Changes: {eval_results['prediction_changes']}\")\n",
    "print(f\"Confidence Decreases: {eval_results['confidence_decreases']}\")\n",
    "print(\"\\nClass-wise Success Rates:\")\n",
    "class_names = data_loader.get_class_names()\n",
    "for class_idx, stats in eval_results['class_success_rates'].items():\n",
    "    if stats['count'] > 0:\n",
    "        print(f\"  {class_names[class_idx]}: {stats['success_rate']:.2f}% ({stats['success']}/{stats['count']})\")\n",
    "print(\"\\nSuccess Rates of Ensemble Members:\")\n",
    "member_names = [\"Base\", \"Texture\", \"Edge\", \"Color\", \"Focal\"]\n",
    "for i, rate in enumerate(eval_results['member_success_rates']):\n",
    "    print(f\"  {member_names[i]}: {rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ensemble_manager.metrics['attack_success_rate'])\n",
    "plt.title('Attack Success Rate During Training')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Success Rate (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(results_dir, run_name, 'attack_success_rate.png'))\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ensemble_manager.metrics['perturbation_norm'])\n",
    "plt.title('L2 Perturbation Norm During Training')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(results_dir, run_name, 'perturbation_norm.png'))\n",
    "plt.show()\n",
    "if ensemble_manager.metrics['ensemble_weights']:\n",
    "    weights_array = np.array(ensemble_manager.metrics['ensemble_weights'])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(5):\n",
    "        plt.plot(weights_array[:, i], label=member_names[i])\n",
    "    plt.title('Evolution of Ensemble Weights')\n",
    "    plt.xlabel('Update Step')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(results_dir, run_name, 'ensemble_weights.png'))\n",
    "    plt.show()\n",
    "member_perf = ensemble_manager.metrics['member_performance']\n",
    "if all(member_perf) and all(perf for perf in member_perf):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(5):\n",
    "        plt.plot(member_perf[i], label=member_names[i])\n",
    "    plt.title('Performance of Ensemble Members')\n",
    "    plt.xlabel('Update Step')\n",
    "    plt.ylabel('Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(results_dir, run_name, 'member_performance.png'))\n",
    "    plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_success = [eval_results['class_success_rates'][i]['success_rate'] for i in range(10)]\n",
    "plt.bar(class_names, class_success)\n",
    "plt.title('Attack Success Rate per Class')\n",
    "plt.ylabel('Success Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, run_name, 'class_success_rates.png'))\n",
    "plt.show()\n",
    "samples_dir = os.path.join(results_dir, run_name, 'evaluation_samples')\n",
    "if os.path.exists(samples_dir):\n",
    "    sample_images = [f for f in os.listdir(samples_dir) if f.endswith('.png')][:6]\n",
    "    if sample_images:\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        for i, img_file in enumerate(sample_images):\n",
    "            img = plt.imread(os.path.join(samples_dir, img_file))\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(img_file.split('.')[0])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml20_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
